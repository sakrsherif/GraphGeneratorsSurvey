\subsection{Graph Analytics}
\label{sec:generators_analytics}

\paragraph{HPC Scalable Graph Analysis Benchmark} The HPC Scalable Graph
Analysis Benchmark~\cite{HPCgraph,Bader:2005:DIH:2099301.2099360} represents an
application with multiple analysis techniques that access a single data
structure representing a weighted, directed graph. The benchmark is composed of
four separated operations (graph construction, classification of large vertex
sets, graph extraction with BFS, and graph analysis with betweenness centrality)
on a graph that follows a power-law distribution. The graph generator constructs a list of edge tuples containing vertex
identifiers (with the edge direction from the first one to the second one) and
weights that represent data assigned to the edges of the multigraph in the form
of positive integers with a uniform random distribution. The generator has the
following parameters: number of vertices, number of edges, and maximum weight of
an edge. The algorithm of the generator is based on R-MAT~\cite{DBLP:conf/sdm/ChakrabartiZF04}. Since the authors aim
to avoid data locality, in the final step the vertex numbers are randomly
permuted, and then edge tuples randomly shuffled. A related project from the same authors developed for the 9th DIMACS Shortest
Paths Challenge is GTgraph~\cite{GTgraph}. It involves three types of graphs:
input graph instances used in the DARPA HPCS SSCA\#2 graph theory benchmark
(version 1.0), Erd\"{o}s-R\'{e}nyi random graphs, and small-world graphs based
on the R-MAT model~\cite{DBLP:conf/sdm/ChakrabartiZF04}. 

Graphalytics~\cite{Iosup:2016:LGB:3007263.3007270} is an industrial-grade benchmark for graph analysis platforms. It involves 6 real-world datasets and 2 synthetic datasets generated that cover two commonly used type of graphs: social network graphs generated using LDBC SNB graph generator (see Section~\ref{sec:generators_socialnetworks}) and power-law graphs generated by Graph500 (see Section~\ref{sec:generators_general}). The benchmark workload consists of 6 deterministic algorithms: breadth-first search, PageRank, weakly connected components, community detection using label propagation, local clustering coefficient, and single-source shortest paths. The benchmark uses various metrics to measure the performance and throughput for systems under test such as \emph{upload time} the measures the required time to preprocess and convert the graph into a suitable format for a graph processing system and \emph{Makespan} the measures the total  execution time of a benchmarking workload algorithm. The benchmark also describes experiments for measuring the scalability of the systems under test. To facilitate the end user job of running the designed experimental workload, the benchmark provides  a performance evaluation framework, \texttt{Granula}\footnote{\url{https://github.com/atlarge-research/granula}}, that consists of three main components: the modeler, the archiver, and the visualizer.


