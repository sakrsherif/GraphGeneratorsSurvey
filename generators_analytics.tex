\subsection{Graph Analytics}
\label{sec:generators_analytics}

Graph analytics, especially in the context of Big Data, is a popular area of studying interesting structural specifics of graphs, usually various types of networks.  Hence, the respective benchmarks and graph data generators developed for the purpose of testing graph analytics tools (such as, e.g.,  PowerGraph~\cite{Gonzalez:2012:PDG:2387880.2387883} or Parallel Graph analytiX~\cite{Sevenich:2016:UDL:3007263.3007265}) have to focus mainly on graphs with complex structures.

\paragraph{HPC Scalable Graph Analysis Benchmark} The HPC Scalable Graph
Analysis Benchmark~\cite{HPCgraph,Bader:2005:DIH:2099301.2099360} consists of a
weighted, directed graph that follows a power-law distribution and four related
analysis techniques (namely graph construction, graph extraction with BFS,
                     classification of large vertex sets, and graph analysis
                     with betweenness centrality). The generator has the
following parameters: the number of vertices, the number of edges, and maximum weight of
an edge. It outputs a list of tuples containing identifiers of vertices of an
edge (with the direction from the first one to the second one) and weights
(positive integers  with a uniform random distribution) assigned to the edges of
the multigraph.  The algorithm of the generator is based on R-MAT. To reduce the data
locality, the vertex ids are randomly permuted and the output
tuples are shuffled. A related project from the same authors
developed for the 9th DIMACS Shortest Paths Challenge is GTgraph~\cite{GTgraph}.
It involves three types of graphs: (1) Erd\"{o}s-R\'{e}nyi random graphs, (2)
different graphs from the DARPA HPCS SSCA\#2 graph theory benchmark
(version 1.0), and (3) small-world graphs generated using the R-MAT graph
generator.

%\paragraph{Graphalytics} Graphalytics\footnote{\url{http://graphalytics.ewi.tudelft.nl/}} is an industrial-grade benchmark for graph analysis platforms~\cite{Iosup:2016:LGB:3007263.3007270}. It involves 6 real-world datasets and 2 synthetic datasets generated so that they cover two commonly used types of graphs: social network graphs generated using LDBC SNB graph generator (see Section~\ref{sec:generators_socialnetworks}) and power-law graphs generated by the Graph 500 benchmark~\cite{Graph500}.\footnote{Hence, we do not involve it in Table~\ref{tab:comparisonCharacteristics}, because it does not bring any new generator.} The benchmark workload consists of 6 deterministic algorithms: breadth-first search, PageRank, weakly connected components, community detection using label propagation, local clustering coefficient, and single-source shortest paths. The benchmark uses various metrics to measure the performance and throughput for systems under test such as \emph{upload time} that measures the required time to preprocess and convert the graph into a suitable format for a graph processing system, or \emph{Makespan} that measures the total  execution time of a benchmarking workload algorithm. The benchmark also describes experiments for measuring the scalability of the systems under test. To facilitate the end user job of running the designed experimental workload, the benchmark provides  a performance evaluation framework, Granula\footnote{\url{https://github.com/atlarge-research/granula}}.%, that consists of three main components: modeler, archiver, and the visualizer.


