\section{Graph Datasets}
\label{sec:data_sets}

Besides graph data generators, many graph algorithms and systems are benchmarked
using real-world graph data sets, including new graph data generation
techniques. In this section, we review those graph datasets most widely used in
the literature and their purpose.

%In general, there exist several types of testing graph data
%sets~\cite{Bachmaier2012}:

\paragraph{Large Scale Graph Analytics}

Large scale graph analytics systems are usually benchmarked using a combination of
real-world and synthetically generated graphs. Because of the rapid evolution of such
systems and their increasing capability to process larger graphs, the datasets
typically used  in the literature quickly change overtime. The most commonly
used datasets (which can be downloaded from several graph dataset
repositories~\cite{snapnets,lawalgo}) are:
\begin{itemize}
  \item \textbf{DBLP}~\cite{yang2015defining}: Represents a co-authorship network where
    researchers from DBLP are represented as vertices and there exists an edge
    between them if they have published a paper together.
  \item \textbf{Amazon}~\cite{yang2015defining}: Represents a product co-purchasing
    network, such that each vertex represents a product, while edges between two products
    exists if a person bought both of them.
  \item \textbf{Road networks}~\cite{leskovec2009community}: Consist of a set of road
    networks from the US.
  \item \textbf{LiveJournal}~\cite{yang2015defining}: A social network where vertices
    represent the users and the edges the acquittances between them.
  \item \textbf{Orkut}~\cite{yang2015defining}: Like LiveJournal, this is a social network
    where vertices represent persons and the edges their friendships.
  \item \textbf{Twitter}~\cite{kwak2010twitter}: This is a directed network representing
    the follower-followee interaction of Twitter.
  \item \textbf{Friendster}~\cite{yang2015defining}: A social network like LiveJournal and
    Orkut, where nodes represent persons and edges their relationships.
  \item \textbf{WebUK}~\cite{delis}: A web graph of the UK subdomain, where nodes represent
    websites and edges represent the hyperlinks between them.
  \item \textbf{ClueWeb2012}~\cite{clueweb}. This is a crawl of the web from 2012, where
    vertices represent websites and the edges represent the hyperlinks connecting them.
\end{itemize}

\paragraph{Recommender Systems}

Many recommender systems are based on graphs, either bipartite graphs or
many-to-many graphs. Such systems are usually tested on several real-world datasets,
many of them containing information about the rating of products or other items such
as movies, books or songs. The following are the most widely used datasets for
testing recommender systems:

\begin{itemize}
\item \textbf{MovieLens}~\cite{movielens}: Consists of a bipartite graph
  between users and movies, where edges represent the ratings the different
  users have made to the movies they watched.
\item \textbf{Book-Crossings}~\cite{ziegler2005improving}: Is a dataset with book ratings
  from users.
\item \textbf{Jester}~\cite{goldberg2001eigentaste}: This dataset contains jokes (with
  their text) and ratings from users.
\item \textbf{Last.fm}~\cite{hetrec}: This dataset contains the list of the top
  most listened artists per user, including the number of times the songs from
  those artists were played. Additionally, it contains connections between users
  (the social network they form), and a set of tags attached to artists that can
  be used to create content vectors.
\item \textbf{Netflix}~\cite{zhou2008large}: This dataset was used during the famous
  Netflix prize. It consists of a bipartite graph with movie ratings from users.
\end{itemize}

\paragraph{Reputation Algorithms}

Another application using social network data is that of assessing the degree of
reputation of a user based on their past interactions and
rankings~\cite{kamvar2003eigentrust,katz2006social,kumar2016edge}. Such
algorithms are typically evaluated on networks with explicit user rankings or
voting from other users, being the most widely used datasets the following
examples:

  \begin{itemize}
    \item \textbf{Bitcoin}~\cite{moore2013beware}: This dataset contains information from
      several Bitcoin exchanges, where users are able to rate other users after
      their transactions. Here, the vertices represent the users and the edges,
      which are labelled, the ratings between them.
    \item \textbf{Wikipedia RFA}~\cite{west2014exploiting}: This network is extracted
      from Wikipedia and the vertices represent users, while the
      edges, which are labelled, the votes emitted by administrators for the
      user to become an administrator.  Each vote is accompanied with a text
      explaining the vote's sign.
    \item \textbf{WikiSigned}~\cite{maniu2011building}: This is a network of Wikipedia
      editors where the vertices are the editors and the edges, which are
      labelled, represent the trust level between two editors.
    \item \textbf{Extended Epinions}~\cite{massa2007trust}: This is an extended version of
      the Epinions network which also contains the levels of distrust between the
      users, expressed by means of edges between them.
    \item \textbf{Twitter Indian Elections}~\cite{kagan2015using}: This network represents
      a Twitter network where vertices represent users and there is an edge
      between two users if a user mentions another one in a tweet. The edges
      are labelled with the average sentiment of one user towards another.
  \end{itemize}


\paragraph{Graph partitioning, Clustering and Community Detection}

Many of the already discussed datasets are also typically used to test and
compare graph partitioning, clustering and community detection algorithms. One
can find a comprehensive list of datasets for such algorithms
in~\cite{10dimacs,yang2015defining}, some of which we have already discussed for other
applications. Here, we summarize the most widely used in the literature:

\begin{itemize}
  \item \textbf{DBLP}, \textbf{Amazon}, \textbf{LiveJournal}, \textbf{Orkut} and \textbf{Friendster}~\cite{yang2015defining}
    are widely used for evaluating community detection since they provide
    information about the meta-communities they contain. For instance, in
    Livejournal, users can join groups of users talking about given topics. Such
    groups are exported as meta-communities, and similar approaches are used for
    other graphs. Community detection algorithms are then evaluated by trying to
    infer such meta-communities without prior knowledge of the user to group
    assignment.
  \item \textbf{Zachary Karate Club}~\cite{zachary1977information}: This graph consists
    of a small network of members of a karate club that was dismissed and split
    into two new karate clubs. Vertices represent persons and edges friendship
    relationships. Information about what people joined each of the two new
    karate clubs is provided.
  \item \textbf{PolBlogs}~\cite{adamic2005political}: This is a network consisting of
    blogs talking about the US 2005 political elections, where a vertex
    represents a blog and the edges the hyperlinks between the blogs. Each blog
    has an associated label, whether it is left or right oriented.
  \item \textbf{PolBooks}~\cite{10dimacs}: Is a network of books of Amazon that talk
    about politics, and edges between two books exist if they are co-purchased
    together. The books have labels of whether they are left or right oriented.
  \item \textbf{Football}~\cite{girvan2002network}: This network represents American university
    football teams. Each node is a football team and the edges are games between teams during the season. Each team is associated to a
    division.
\end{itemize}

\paragraph{Information Diffusion}

Information networks are studied using graph algorithms in order to understand
how information propagates. As such, there several datasets used to understand
such networks.

\begin{itemize}
  \item \textbf{Higgs-Twitter}~\cite{de2013anatomy}: This dataset contains the Twitter
    network before, during and after the discovery of the Higgs boson.
    Specifically, it contains the tweets, the mentions, retweets,
    followers/followees, etc.
  \item \textbf{Memetracker}~\cite{leskovec2009meme}: Memetracker is a dataset that
    contains the quotes and phrases that appear more frequently on the entire
    news spectrum. It consists of the links of the news, the time and memes, and
    is used to understand how information spawns, evolves and dies.
\end{itemize}

\paragraph{Semantic Web and Knowledge bases}

Semantic web and RDF engines have a well accepted set of real-world datasets, used to
test reasoning engines as well as to use as baselines for the creation of new
synthetic generators for the semantic web.

\begin{itemize}
  \item \textbf{DbPedia}~\cite{Bizer:2009:DCP:1640541.1640848}: The DBPedia project aims at creating
    a structured version of Wikipedia. It allows users to semantically query the
    relationships between the different resources at Wikipedia.
  \item \textbf{Freebase}~\cite{bollacker2008freebase}: This is a collaborative knowledge base
    made of metadata maintained by community members. It contains
    structured data from multiple sources in an attempt to create a global
    resource of information accessible both from persons and machines. The
    project was discontinued in 2014 and replaced by Wikidata.
  \item \textbf{Yago}~\cite{suchanek2007yago}, \textbf{Yago2}~\cite{hoffart2013yago2} \&
    \textbf{Yago3}~\cite{mahdisoltani2013yago3}: These are
    open source knowledge bases developed at the Max Planck Institute of
    Computer Science in Saarbr\"ucken. They contain structured data  that has been automatically extracted
    from Wikipedia and other sources.
  \item \textbf{Wikidata}~\cite{vrandevcic2014wikidata}: This is a knowledge base
    collaboratively edited by the community and hosted by the Wikimedia
    Foundation. It contains structured data from other related projects such as Wikipedia,
    Wikivoyage or Wikisource.
  \item \textbf{Billion Triple Challenge}~\cite{btc-2014}: This is a semantic dataset
    crawled from different sources, including Freebase, DBPedia or the BBC. A
    detailed description of the crawling process can be found in~\cite{kafer2012towards}.
\end{itemize}

%\begin{itemize}
%  \item A real-world data set which represents a graph, such as
%      the Internet Movie Database (IMDb)\footnote{\url{http://www.imdb.com/}} or
%      various data sets available in the Stanford Large Network Dataset
%      Collection~\cite{snapnets},
%    \item A general graphbase, such as the Open
%      Graph Archive~\cite{Bachmaier2012}, the Stanford
%    GraphBase~\cite{Knuth:1993:SGP:164984}, or the
%  GraphArchive~\cite{GraphArchive},
%\item A dataset dedicated to specific
%    experimental goals, such as graph partitioning and graph
%    clustering~\cite{10dimacs}, shortest paths~\cite{9dimacs}, or graph
%    coloring~\cite{coloring}, and
%  \item A dataset devoted to matrices, such as
%the SuiteSparse Matrix Collection~\cite{SuiteSparse} or  the Matrix
%Market~\cite{MatrixMarket}.
%\end{itemize}
